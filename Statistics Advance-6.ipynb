{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ed9935f-cd4a-4472-8445-f55c9c453a12",
   "metadata": {},
   "source": [
    "# Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results.\n",
    "# Answer :->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01414427-c8a9-43b3-8779-610f01f969a6",
   "metadata": {},
   "source": [
    "### Certainly! Analysis of Variance (ANOVA) is a statistical technique used to compare means among multiple groups. For reliable results, several assumptions must be met. Here are the key assumptions and examples of potential violations:\n",
    "\n",
    "# Normality Assumption:\n",
    "\n",
    "1. Assumption: The data within each group should follow a normal distribution.\n",
    "2. Violation Example: If the data in one or more groups are skewed or exhibit a non-normal distribution, it can lead to inaccurate results. This assumption is often checked using normality tests like the Shapiro-Wilk test.\n",
    "\n",
    "# Homogeneity of Variance (Homoscedasticity):\n",
    "\n",
    "1. Assumption: The variances of the groups being compared should be approximately equal.\n",
    "2. Violation Example: Unequal variances across groups can lead to unreliable F-tests. If one group has significantly larger variance than others, it may dominate the ANOVA results.\n",
    "\n",
    "# Independence of Observations:\n",
    "\n",
    "1. Assumption: Observations within each group must be independent of each other.\n",
    "2. Violation Example: In cases where observations are not independent, such as repeated measures or nested designs, it may violate the independence assumption. For example, measuring the same individuals over time or across related groups could lead to dependence.\n",
    "\n",
    "# Random Sampling/Assignment:\n",
    "\n",
    "1. Assumption: Data should ideally be collected through random sampling or random assignment in experimental designs.\n",
    "2. Violation Example: If groups are not formed through random processes, there may be systematic differences between groups that are not accounted for in the analysis.\n",
    "\n",
    "# Interval or Ratio Scale Data:\n",
    "\n",
    "1. Assumption: The dependent variable should be measured on an interval or ratio scale.\n",
    "2. Violation Example: If the dependent variable is measured on an ordinal scale or is not continuous, using ANOVA may not be appropriate.\n",
    "\n",
    "# Additivity and Linearity:\n",
    "\n",
    "1. Assumption: The relationship between the independent and dependent variables is linear and additive.\n",
    "2. Violation Example: If the relationship is non-linear, ANOVA results may be misleading. Transformation of variables or using non-parametric alternatives might be considered in such cases.\n",
    "\n",
    "# No Perfect Multicollinearity:\n",
    "\n",
    "1. Assumption: For factorial ANOVA, there should be no perfect linear relationship between the independent variables.\n",
    "2. Violation Example: If there is perfect multicollinearity (i.e., one independent variable is a perfect linear combination of others), it can lead to unreliable parameter estimates.\n",
    "\n",
    "### It's important to assess these assumptions before interpreting ANOVA results. In case of violations, alternative methods, such as non-parametric tests or transformations, might be considered. Additionally, graphical methods like residual plots can be helpful in diagnosing violations of assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42272a70-708c-49b4-a69e-94b166fed8fa",
   "metadata": {},
   "source": [
    "# Q2. What are the three types of ANOVA, and in what situations would each be used?\n",
    "# Answer :->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a8f95b-d4c9-4fdd-988f-b4c1a7b63de8",
   "metadata": {},
   "source": [
    "### There are three main types of Analysis of Variance (ANOVA), each designed to address specific experimental or research designs. The three types of ANOVA are:\n",
    "\n",
    "# One-Way ANOVA:\n",
    "\n",
    "1. Use Case: One-Way ANOVA is used when there is one independent variable with more than two levels or groups, and the goal is to compare the means of these groups to determine if there are any statistically significant differences.\n",
    "2. Example: Suppose a researcher wants to compare the mean scores of three different teaching methods (Group A, Group B, and Group C) to determine if there is a significant difference in student performance.\n",
    "\n",
    "# Two-Way ANOVA:\n",
    "\n",
    "1. Use Case: Two-Way ANOVA is an extension of One-Way ANOVA and is used when there are two independent variables (factors). It assesses whether there are any interactive effects between the two factors on the dependent variable, in addition to main effects of each factor.\n",
    "2. Example: Consider a study examining the effects of both gender (Male/Female) and a treatment (Treatment A, Treatment B) on exam scores. Two-Way ANOVA would test for the main effects of gender and treatment, as well as their interaction.\n",
    "\n",
    "# Repeated Measures ANOVA:\n",
    "\n",
    "1. Use Case: Repeated Measures ANOVA is used when measurements are taken on the same group or individual over multiple time points or conditions. It is suitable for within-subject designs where the same subjects are measured under different conditions.\n",
    "2. Example: In a study measuring blood pressure before and after treatment within the same group of individuals, Repeated Measures ANOVA would be appropriate to assess whether there are significant changes over time.\n",
    "\n",
    "#### In summary:\n",
    "\n",
    "## One-Way ANOVA: Compares means across three or more groups of a single independent variable.\n",
    "## Two-Way ANOVA: Examines the influence of two independent variables on a dependent variable and assesses interaction effects.\n",
    "## Repeated Measures ANOVA: Analyzes repeated measurements or observations taken on the same subjects or groups over time or under different conditions.\n",
    "#### Choosing the appropriate type of ANOVA depends on the experimental design and the number of independent variables. Researchers need to carefully consider their study design and the nature of their data to select the most suitable ANOVA method.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6bee0c-20f7-425e-9894-c5bababa48d6",
   "metadata": {},
   "source": [
    "# Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?\n",
    "# Answer :->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7325b375-36cb-451e-a95d-bdb2470ee870",
   "metadata": {
    "tags": []
   },
   "source": [
    "### The partitioning of variance in Analysis of Variance (ANOVA) refers to the process of decomposing the total variance observed in the data into different components. Understanding this concept is crucial because it provides insights into the sources of variability in the data and helps in evaluating the significance of the factors being studied. The total variance in the data is divided into three main components in the context of ANOVA:\n",
    "\n",
    "# Total Variance (Total Sum of Squares - SST):\n",
    "\n",
    "#### This represents the overall variability in the dependent variable across all observations. Mathematically, it is the sum of the squared differences between each individual data point and the overall mean.\n",
    "\n",
    "## SST=∑(Yi − Yˉ)**2\n",
    "\n",
    "# Between-Group Variance (Between-Group Sum of Squares - SSB):\n",
    "\n",
    "#### This component represents the variability in the dependent variable that can be attributed to differences between the group means. It measures how much the group means differ from the overall mean.\n",
    "\n",
    "## SSB=∑nj(Yˉj − Yˉ)**2 \n",
    "\n",
    "#### where k is the number of groups, nj is the sample size of the j-th group, Yˉj is the mean of the j-th group, and Yˉis the overall mean.\n",
    "\n",
    "# Within-Group Variance (Within-Group Sum of Squares - SSW):\n",
    "\n",
    "#### This component represents the variability in the dependent variable that is not explained by differences between group means. It \n",
    "\n",
    "# SSW=∑  ∑  (Yij − Yˉj)**2\n",
    "#### where Yij is the i-th observation in the j-th group,  is the mean of the j-th group, and nj is the sample size of the j-th group.\n",
    "\n",
    "#### The key relationship is given by:\n",
    "\n",
    "# SST = SSB + SSW\n",
    "\n",
    "## Understanding the partitioning of variance is important for several reasons:\n",
    "\n",
    "#### Identification of Sources of Variability: It helps identify whether the variability in the dependent variable is primarily due to differences between groups or within groups.\n",
    "\n",
    "#### Assessment of Group Differences: By comparing the between-group variance to the within-group variance, ANOVA determines whether the group means are significantly different from each other.\n",
    "\n",
    "#### Calculation of F-statistic: The ratio of between-group variance to within-group variance (F-statistic) is used to test the hypothesis of whether the group means are equal.\n",
    "\n",
    "#### Effect Size Estimation: It provides a basis for calculating effect sizes, such as eta-squared, which quantifies the proportion of total variance explained by group differences.\n",
    "\n",
    "#### In summary, understanding the partitioning of variance in ANOVA is essential for interpreting the results, making informed statistical inferences, and gaining insights into the factors contributing to variability in the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d847e2-57a2-440b-90c2-30e74854a72c",
   "metadata": {},
   "source": [
    "# Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?\n",
    "# Answer :->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48ba838b-3561-4553-9a4a-437e690bba24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sum of Squares (SST): 505.59999999999997\n",
      "Explained Sum of Squares (SSE): 420.4000000000001\n",
      "Residual Sum of Squares (SSR): 85.19999999999999\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sample data (replace this with your actual data)\n",
    "group1 = np.array([23, 25, 27, 22, 20])\n",
    "group2 = np.array([30, 32, 28, 35, 33])\n",
    "group3 = np.array([18, 15, 20, 19, 22])\n",
    "\n",
    "# Combine data from all groups\n",
    "all_data = np.concatenate([group1, group2, group3])\n",
    "\n",
    "# Calculate overall mean\n",
    "overall_mean = np.mean(all_data)\n",
    "\n",
    "# Calculate Total Sum of Squares (SST)\n",
    "sst = np.sum((all_data - overall_mean)**2)\n",
    "\n",
    "# Calculate group means\n",
    "group_means = np.array([np.mean(group) for group in [group1, group2, group3]])\n",
    "\n",
    "# Calculate Explained Sum of Squares (SSE)\n",
    "sse = np.sum([len(group) * (mean - overall_mean)**2 for group, mean in zip([group1, group2, group3], group_means)])\n",
    "\n",
    "# Calculate Residual Sum of Squares (SSR)\n",
    "ssr = np.sum([(value - group_means[i])**2 for i, group in enumerate([group1, group2, group3]) for value in group])\n",
    "\n",
    "print(\"Total Sum of Squares (SST):\", sst)\n",
    "print(\"Explained Sum of Squares (SSE):\", sse)\n",
    "print(\"Residual Sum of Squares (SSR):\", ssr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966cd738-10af-45d3-8e79-f9c882b78144",
   "metadata": {},
   "source": [
    "# Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?\n",
    "# answer :->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "477feb0f-6546-41b8-a308-2a1f43bd880d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Effect for Factor1: 28.125000000000107\n",
      "Main Effect for Factor2: 3.1250000000000044\n",
      "Interaction Effect: 1.1250000000000036\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Simulated data (replace this with your actual data)\n",
    "data = {'Factor1': ['A', 'A', 'B', 'B', 'A', 'A', 'B', 'B'],\n",
    "        'Factor2': ['X', 'Y', 'X', 'Y', 'X', 'Y', 'X', 'Y'],\n",
    "        'DependentVariable': [10, 12, 15, 14, 18, 20, 22, 24]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fit two-way ANOVA model\n",
    "formula = 'DependentVariable ~ Factor1 + Factor2 + Factor1:Factor2'\n",
    "model = ols(formula, data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Extract main effects and interaction effect\n",
    "main_effect_factor1 = anova_table['sum_sq']['Factor1'] / anova_table['df']['Factor1']\n",
    "main_effect_factor2 = anova_table['sum_sq']['Factor2'] / anova_table['df']['Factor2']\n",
    "interaction_effect = anova_table['sum_sq']['Factor1:Factor2'] / anova_table['df']['Factor1:Factor2']\n",
    "\n",
    "print(\"Main Effect for Factor1:\", main_effect_factor1)\n",
    "print(\"Main Effect for Factor2:\", main_effect_factor2)\n",
    "print(\"Interaction Effect:\", interaction_effect)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19702f4b-5137-4c3b-a2cc-dadd4a8f244b",
   "metadata": {},
   "source": [
    "# Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. What can you conclude about the differences between the groups, and how would you interpret these results?\n",
    "# Answer :->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5a4df1-9036-424f-be94-61aeec52dae2",
   "metadata": {},
   "source": [
    "### In a one-way ANOVA, the F-statistic is used to test the null hypothesis that the means of several groups are equal. The p-value associated with the F-statistic helps determine whether to reject or fail to reject the null hypothesis. Here's how you can interpret the results:\n",
    "\n",
    "## F-Statistic:\n",
    "#### In your case, the F-statistic is 5.23. This value represents the ratio of the variance between groups to the variance within groups. A higher F-statistic indicates a larger difference between group means relative to the variability within each group.\n",
    "\n",
    "## P-Value:\n",
    "#### The p-value associated with the F-statistic is 0.02. This is the probability of observing such extreme results (or more extreme) under the assumption that the null hypothesis is true.\n",
    "\n",
    "#### Now, let's interpret the results:\n",
    "\n",
    "### Null Hypothesis (H0): The means of all groups are equal.\n",
    "### Alternative Hypothesis (Ha): At least one group mean is different from the others.\n",
    "\n",
    "## Interpretation:\n",
    "\n",
    "### P-Value < Significance Level (e.g., 0.05):\n",
    "\n",
    "#### Since the p-value (0.02) is less than the commonly used significance level (e.g., 0.05), you would reject the null hypothesis.\n",
    "\n",
    "## Conclusion:\n",
    "\n",
    "### There is sufficient evidence to suggest that at least one group mean is different from the others.\n",
    "\n",
    "## Practical Significance:\n",
    "\n",
    "#### It's important to consider not only statistical significance but also practical significance. Even though there is a statistically significant difference, the practical importance of this difference should be assessed in the context of the specific study.\n",
    "\n",
    "## Post-hoc Tests (if applicable):\n",
    "\n",
    "#### If you have more than two groups and reject the null hypothesis, it's common to perform post-hoc tests (e.g., Tukey's HSD or Bonferroni correction) to identify which specific groups differ from each other.\n",
    "\n",
    "## Effect Size:\n",
    "\n",
    "### Consider calculating and reporting effect size measures (e.g., eta-squared) to quantify the magnitude of the observed differences.\n",
    "\n",
    "#### In summary, based on the given F-statistic and p-value, you would reject the null hypothesis, suggesting that there are statistically significant differences between at least some of the groups. Further analysis, including post-hoc tests and consideration of effect size, can provide additional insights into the nature and practical importance of these differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62796969-8538-4c72-812e-99b0539ed05d",
   "metadata": {},
   "source": [
    "# Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?\n",
    "# Answer :->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554c79ae-6f4c-4903-8463-dd58f91c5f2b",
   "metadata": {},
   "source": [
    "### Handling missing data in a repeated measures ANOVA is an important consideration as it can impact the validity and reliability of the analysis. There are several methods to handle missing data, and the choice of method can have consequences for the results. Here are some common approaches and their potential consequences:\n",
    "\n",
    "# Methods to Handle Missing Data:\n",
    "## Complete Case Analysis (Listwise Deletion):\n",
    "\n",
    "###  Approach: Exclude cases with missing data.\n",
    "### Consequences:\n",
    "1. Reduces the sample size, potentially leading to reduced statistical power.\n",
    "2. May introduce bias if missing data are not missing completely at random (MCAR).\n",
    "\n",
    "## Mean Imputation:\n",
    "\n",
    "### Approach: Replace missing values with the mean of the observed values for that variable.\n",
    "### Consequences:\n",
    "1. Preserves the sample size but may distort the distribution and variance of the variable.\n",
    "2. Does not account for variability in missing values.\n",
    "\n",
    "## Last Observation Carried Forward (LOCF):\n",
    "\n",
    "### Approach: Replace missing values with the last observed value.\n",
    "### Consequences:\n",
    "1. Assumes that the last observed value is a good estimate of the missing value.\n",
    "2. Can lead to biased results, especially if the missing values are not monotonic.\n",
    "\n",
    "## Linear Interpolation:\n",
    "\n",
    "### Approach: Estimate missing values based on a linear interpolation between adjacent observed values.\n",
    "### Consequences:\n",
    "1. Assumes a linear relationship between observed values, which may not be appropriate in all cases.\n",
    "2. Sensitive to extreme values.\n",
    "\n",
    "## Multiple Imputation:\n",
    "### Approach: Impute missing values multiple times to generate several complete datasets, perform analyses on each dataset, and then combine results.\n",
    "### Consequences:\n",
    "1. Accounts for uncertainty associated with missing data.\n",
    "2. Requires more sophisticated statistical techniques and assumptions.\n",
    "\n",
    "# Potential Consequences:\n",
    "## Bias:\n",
    "1. Different methods can introduce bias if they make assumptions about the missing data mechanism (MCAR, MAR, MNAR) that do not hold.\n",
    "\n",
    "## Loss of Power:\n",
    "1. Complete case analysis and other methods that reduce the sample size may result in lower statistical power.\n",
    "\n",
    "## Invalid Assumptions:\n",
    "1. Some imputation methods assume a specific pattern or relationship in the missing data that may not reflect reality.\n",
    "\n",
    "## Underestimation of Variability:\n",
    "1. Mean imputation and LOCF can lead to underestimation of the variability in the data.\n",
    "\n",
    "## Inflated Type I Error Rates:\n",
    "1. In some cases, certain imputation methods can lead to inflated Type I error rates.\n",
    "\n",
    "# Best Practices:\n",
    "\n",
    "## Understand the Missing Data Mechanism:\n",
    "1. Assess whether the missing data are missing completely at random (MCAR), missing at random (MAR), or missing not at random (MNAR).\n",
    "\n",
    "## Consider Multiple Imputation:\n",
    "1. If feasible, multiple imputation is generally preferred as it accounts for uncertainty associated with missing data.\n",
    "\n",
    "## Sensitivity Analysis:\n",
    "1. Conduct sensitivity analyses using different imputation methods to assess the robustness of the results.\n",
    "\n",
    "## Transparency:\n",
    "1. Clearly document the method used for handling missing data and acknowledge its limitations in the interpretation of results.\n",
    "\n",
    "### Ultimately, the choice of how to handle missing data should be guided by the specific characteristics of the data, the missing data mechanism, and the goals of the analysis. It's crucial to approach missing data with caution and transparency in reporting the chosen method and its potential impact on the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af5a796-6627-4260-b530-f0fc7e35fcb8",
   "metadata": {},
   "source": [
    "# Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary.\n",
    "# Answer :->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a74054-3a2b-49f0-8ba6-71042e2dc6ec",
   "metadata": {},
   "source": [
    "### Post-hoc tests are used after conducting an Analysis of Variance (ANOVA) to further investigate significant differences among multiple groups. ANOVA can determine whether there are any statistically significant differences among the means of three or more independent (unrelated) groups. When the ANOVA reveals a significant difference, post-hoc tests are employed to identify which specific group or groups differ from each other.\n",
    "\n",
    "### Here are some common post-hoc tests and situations where they might be used:\n",
    "\n",
    "# Tukey's Honestly Significant Difference (HSD):\n",
    "1. When to use: Tukey's HSD is a conservative test that is suitable when you have a larger number of groups and you want to control the overall Type I error rate.\n",
    "2. Example: Suppose you conduct an ANOVA to compare the mean scores of students from three different teaching methods (A, B, and C). If the ANOVA indicates a significant difference, you can use Tukey's HSD to identify which pairs of teaching methods have significantly different mean scores.\n",
    "\n",
    "# Bonferroni Correction:\n",
    "1. When to use: Bonferroni correction is often used when you have a smaller number of planned comparisons or when there is concern about an inflated Type I error rate.\n",
    "2. Example: Continuing with the teaching methods example, if you are specifically interested in comparing Method A to Method B, Method A to Method C, and Method B to Method C, you might use Bonferroni correction to adjust the significance level for each of these three comparisons.\n",
    "\n",
    "# Scheffé's Test:\n",
    "1. When to use: Scheffé's test is used when you have a large number of groups and you want to maintain a balance between the risk of Type I and Type II errors.\n",
    "2. Example: Imagine a scenario where you are comparing the mean performance of athletes in multiple training programs. If ANOVA indicates a significant difference, you could use Scheffé's test to identify which training programs lead to significantly different performance.\n",
    "\n",
    "# Dunnett's Test:\n",
    "1. When to use: Dunnett's test is appropriate when comparing multiple treatment groups to a single control group.\n",
    "2. Example: If you are testing the effectiveness of three different drugs compared to a control group, and ANOVA shows a significant difference, you could use Dunnett's test to determine which drug(s) significantly differ from the control group.\n",
    "\n",
    "# Holm's Method:\n",
    "1. When to use: Holm's method is a step-down procedure that can be used in situations where the number of comparisons is not known in advance.\n",
    "2. Example: Suppose you are comparing the mean scores of patients under different treatment conditions. Holm's method can be applied when you have a flexible number of pairwise comparisons to make between the treatments.\n",
    "\n",
    "### Example Situation:\n",
    "#### Let's say you conduct an ANOVA to analyze the average scores of students who studied under different tutoring methods (A, B, C, and D). The ANOVA result is statistically significant, indicating that at least one tutoring method differs from the others. In this scenario, you would use a post-hoc test, such as Tukey's HSD or Bonferroni correction, to identify the specific pairs of tutoring methods that exhibit significant differences in mean scores. This helps you pinpoint which tutoring methods are more effective or whether they are all significantly different from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb33f808-9407-4809-b29b-1fc9edafe398",
   "metadata": {},
   "source": [
    "# Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of the three diets. Report the F-statistic and p-value, and interpret the results.\n",
    "# Answer :->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0272afba-44c8-42c2-8d50-31e2f5b3383d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 16.574213049400626\n",
      "P-value: 3.2283781469409867e-07\n",
      "There is a significant difference in the mean weight loss between at least two of the diets.\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "# Generate hypothetical weight loss data for three diets\n",
    "np.random.seed(42)  # Set seed for reproducibility\n",
    "weight_loss_A = np.random.normal(loc=5, scale=2, size=50)\n",
    "weight_loss_B = np.random.normal(loc=6, scale=2, size=50)\n",
    "weight_loss_C = np.random.normal(loc=4, scale=2, size=50)\n",
    "\n",
    "# Combine data into a single array\n",
    "weight_loss_data = np.concatenate([weight_loss_A, weight_loss_B, weight_loss_C])\n",
    "\n",
    "# Create corresponding group labels\n",
    "groups = ['A'] * 50 + ['B'] * 50 + ['C'] * 50\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(weight_loss_A, weight_loss_B, weight_loss_C)\n",
    "\n",
    "# Report results\n",
    "print(f\"F-statistic: {f_statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpretation\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"There is a significant difference in the mean weight loss between at least two of the diets.\")\n",
    "else:\n",
    "    print(\"There is no significant difference in the mean weight loss between the diets.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21c98b7-773e-453e-ae62-c6b73fb55f7d",
   "metadata": {},
   "source": [
    "# Q10. A company wants to know if there are any significant differences in the average time it takes to complete a task using three different software programs: Program A, Program B, and Program C. They randomly assign 30 employees to one of the programs and record the time it takes each employee to complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or interaction effects between the software programs and employee experience level (novice vs. experienced). Report the F-statistics and p-values, and interpret the results.\n",
    "# Answer :->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce7b7bfc-0060-4c65-b9ae-eb168697c662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: statsmodels in /opt/conda/lib/python3.10/site-packages (0.13.5)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.10/site-packages (from statsmodels) (22.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /opt/conda/lib/python3.10/site-packages (from statsmodels) (0.5.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from statsmodels) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.3 in /opt/conda/lib/python3.10/site-packages (from statsmodels) (1.9.3)\n",
      "Requirement already satisfied: pandas>=0.25 in /opt/conda/lib/python3.10/site-packages (from statsmodels) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.25->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.25->statsmodels) (2022.6)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from patsy>=0.5.2->statsmodels) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae62a5af-a089-4485-9c49-9b5bdcde54dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               sum_sq    df         F    PR(>F)\n",
      "C(Software)                  1.334021   2.0  0.193670  0.824297\n",
      "C(Experience)                5.096305   1.0  1.479736  0.227223\n",
      "C(Software):C(Experience)    8.396750   2.0  1.219018  0.300694\n",
      "Residual                   289.301266  84.0       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Generate hypothetical data\n",
    "np.random.seed(42)\n",
    "\n",
    "# Creating data frame\n",
    "data = pd.DataFrame({\n",
    "    'Software': np.random.choice(['A', 'B', 'C'], size=90),\n",
    "    'Experience': np.random.choice(['Novice', 'Experienced'], size=90),\n",
    "    'Time': np.random.normal(loc=10, scale=2, size=90)\n",
    "})\n",
    "\n",
    "# Perform two-way ANOVA with interaction term\n",
    "model = ols('Time ~ C(Software) * C(Experience)', data=data).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Report results\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1587247-661f-48cd-8c52-05a5c23e2fc0",
   "metadata": {},
   "source": [
    "# Q11. An educational researcher is interested in whether a new teaching method improves student test scores. They randomly assign 100 students to either the control group (traditional teaching method) or the experimental group (new teaching method) and administer a test at the end of the semester. Conduct a two-sample t-test using Python to determine if there are any significant differences in test scores between the two groups. If the results are significant, follow up with a post-hoc test to determine which group(s) differ significantly from each other.\n",
    "\n",
    "# Answer :->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5c5453a-4718-4c90-acf0-7f18d11f9d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: -4.108723928204809\n",
      "P-value: 8.261945608702611e-05\n",
      "There is a significant difference in test scores between the control and experimental groups.\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "# Generate hypothetical test score data\n",
    "np.random.seed(42)\n",
    "\n",
    "control_group = np.random.normal(loc=70, scale=10, size=50)\n",
    "experimental_group = np.random.normal(loc=75, scale=10, size=50)\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(control_group, experimental_group)\n",
    "\n",
    "# Report results\n",
    "print(\"T-statistic:\", t_statistic)\n",
    "print(\"P-value:\", p_value)\n",
    "\n",
    "# Interpretation\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"There is a significant difference in test scores between the control and experimental groups.\")\n",
    "else:\n",
    "    print(\"There is no significant difference in test scores between the groups.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1c26d4-457e-4c6e-b4a1-e8fcfac29905",
   "metadata": {},
   "source": [
    "# Q12. A researcher wants to know if there are any significant differences in the average daily sales of three retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store on those days. Conduct a repeated measures ANOVA using Python to determine if there are any significant differences in sales between the three stores. If the results are significant, follow up with a post- hoc test to determine which store(s) differ significantly from each other.\n",
    "\n",
    "# Answer :->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56f4850d-ebad-4e96-bf29-346c53f11e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 3.617680723218871\n",
      "P-value: 0.030958706725161763\n",
      "There is a significant difference in daily sales between at least two of the stores.\n",
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05    \n",
      "==========================================================\n",
      "group1 group2  meandiff p-adj    lower      upper   reject\n",
      "----------------------------------------------------------\n",
      "     A      B  566.9844 0.0567    -12.857 1146.8258  False\n",
      "     A      C    1.0317    1.0  -578.8098  580.8731  False\n",
      "     B      C -565.9528 0.0573 -1145.7942   13.8887  False\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "# Generate hypothetical daily sales data\n",
    "np.random.seed(42)\n",
    "\n",
    "sales_A = np.random.normal(loc=5000, scale=1000, size=30)\n",
    "sales_B = np.random.normal(loc=5500, scale=1000, size=30)\n",
    "sales_C = np.random.normal(loc=4800, scale=1000, size=30)\n",
    "\n",
    "# Combine data into a single array\n",
    "sales_data = np.concatenate([sales_A, sales_B, sales_C])\n",
    "\n",
    "# Create corresponding group labels\n",
    "groups = ['A'] * 30 + ['B'] * 30 + ['C'] * 30\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(sales_A, sales_B, sales_C)\n",
    "\n",
    "# Report results\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"P-value:\", p_value)\n",
    "\n",
    "# Interpretation\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"There is a significant difference in daily sales between at least two of the stores.\")\n",
    "    \n",
    "    # Follow up with a post-hoc test (e.g., Tukey's HSD)\n",
    "    from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "    \n",
    "    posthoc = pairwise_tukeyhsd(sales_data, groups)\n",
    "    print(posthoc.summary())\n",
    "else:\n",
    "    print(\"There is no significant difference in daily sales between the stores.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaee82b-e145-41cd-8b71-3a40d855f76f",
   "metadata": {},
   "source": [
    "#  ---------------------------------------   Thank You   ------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fe92e7-7ffe-4d19-adc0-4a9d0eecc9be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
